{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f684eb0-16ee-4532-8f6e-0c9070afedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import tfod\n",
    "import bbox_prep\n",
    "import detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83030f9d-ed01-491f-a4c0-bf1559ad643f",
   "metadata": {},
   "source": [
    "#### Detection Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632db52d-031c-4a69-b240-f5f7a8ec93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to base folder \n",
    "MAIN_FOLDER = pathlib.Path(\"./Main_Folder\")\n",
    "\n",
    "''' Detection Constants '''\n",
    "# Path to label map\n",
    "LABEL_PATH = pathlib.Path(\"./Tensorflow/workspace/training_demo/annotations/label_map.pbtxt\")\n",
    "# Path to pipeline file\n",
    "CONFIG_PATH = pathlib.Path(\"./Tensorflow/workspace/training_demo/models/bbox_efficientdet1_v2/pipeline.config\")\n",
    "# Path to checkpoint file\n",
    "CKPT_PATH = \"./Tensorflow/workspace/training_demo/models/bbox_efficientdet1_v2/ckpt-21\".encode('utf-8')\n",
    "# Path to image folder. Do for pos and neg seperately\n",
    "IMAGE_PATH = MAIN_FOLDER / \"Main data/pos_images\"\n",
    "# Path to the csv to save bboxes in\n",
    "CSV_NAME = IMAGE_PATH / \"bboxes_ckpt21.csv\"\n",
    "# Resize all images to this before detection. Is set manually to have uniform images\n",
    "PREF_SIZE = (1500, 1500) \n",
    "\n",
    "''' Bbox preperation constants '''\n",
    "CONTRAST_FACTORS = [1.3, 1.5, 1.7]\n",
    "CUT_IMAGE_SIZE = (220, 220)\n",
    "CUT_SAVE_ADDRESS = IMAGE_PATH / \"noCrownCrop\"    # address to save croppped images\n",
    "\n",
    "''' Classification Constants '''\n",
    "# Seperate left and right side images to perform classification on them. Choosing contrast1.5 images is suggested. \n",
    "LEFT_IMAGES_PATH = pathlib.Path(\"\")               \n",
    "RIGHT_IMAGES_PATH = pathlib.Path(\"\")\n",
    "MODEL_LOAD_FOLDER = pathlib.Path(\"F:\\ML\\\\venv3.9\\Scripts\\\\Dr Fahim\\\\CNN Model\\\\kfold_saves\\\\automated\\\\random_aug\")\n",
    "MODEL_ADDRESS = MODEL_LOAD_FOLDER / \"model name\"   # Set the model name\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfb13f-ff64-49e8-883b-019f7ca97185",
   "metadata": {},
   "source": [
    "#### Tensorflow Object Detection, efficientdet_d1_coco17_tpu-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b08d7a-454c-45ed-a54f-6c0b656422d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection of 0 files done, 34 remaining.\n",
      "Detection of 5 files done, 29 remaining.\n",
      "Detection of 10 files done, 24 remaining.\n",
      "Detection of 15 files done, 19 remaining.\n",
      "Detection of 20 files done, 14 remaining.\n",
      "Detection of 25 files done, 9 remaining.\n",
      "BBox Detection of 34 files finished.\n"
     ]
    }
   ],
   "source": [
    "image_list = list(IMAGE_PATH.glob(\"./*.png\"))\n",
    "tfod_instance = tfod.Tfod_User(CONFIG_PATH, CKPT_PATH, LABEL_PATH, image_list, PREF_SIZE, CSV_NAME)\n",
    "tfod_instance.model_loader()\n",
    "tfod_instance.detection_batched()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "del tfod_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bd812-a0c8-4c2e-999d-a99cb138c2e2",
   "metadata": {},
   "source": [
    "#### Boundig Box Preparation to cut images and save them in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc3629d-b78e-4730-936c-ea7f2b169e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Files saved in F:\\ML\\venv3.9\\Scripts\\Dr Fahim\\Main data\\positive 8\\noCrownCrop\\original\n",
      "34 Files saved in F:\\ML\\venv3.9\\Scripts\\Dr Fahim\\Main data\\positive 8\\noCrownCrop\\contrast1.3\n",
      "34 Files saved in F:\\ML\\venv3.9\\Scripts\\Dr Fahim\\Main data\\positive 8\\noCrownCrop\\contrast1.5\n",
      "34 Files saved in F:\\ML\\venv3.9\\Scripts\\Dr Fahim\\Main data\\positive 8\\noCrownCrop\\contrast1.7\n"
     ]
    }
   ],
   "source": [
    "image_list = list(IMAGE_PATH.glob(\"./*.png\"))\n",
    "if not os.path.isdir(CUT_SAVE_ADDRESS):\n",
    "    os.mkdir(CUT_SAVE_ADDRESS)\n",
    "\n",
    "bbox_instance = bbox_prep.Bbox_User(image_list, CSV_NAME, IMAGE_PATH, CUT_SAVE_ADDRESS, CONTRAST_FACTORS, prefix=\"c\", size=CUT_IMAGE_SIZE)\n",
    "bbox_instance.auto_handler()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a766c95-d75f-4ebb-a0b3-50d84f33531b",
   "metadata": {},
   "source": [
    "#### Classification: Predict and save result in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678f7ac-b011-4b89-a1ae-64d05ec5c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_images = list(LEFT_IMAGES_PATH.glob(\"./*.png\"))\n",
    "right_images = list(RIGHT_IMAGES_PATH.glob(\"./*.png\"))\n",
    "if len(left_images):\n",
    "    csv_name_left = MAIN_FOLDER / \"Classification Result Left.csv\"\n",
    "    classifier_instance = detector.Model_Handler(MODEL_ADDRESS, left_images, csv_name_left, (220, 220), \"left\", BATCH_SIZE)\n",
    "    classifier_instance.auto_handler()\n",
    "if len(right_images):\n",
    "    csv_name_right = MAIN_FOLDER / \"Classification Result Right.csv\"\n",
    "    classifier_instance = detector.Model_Handler(MODEL_ADDRESS, right_images, csv_name_right, (220, 220), \"right\", BATCH_SIZE)\n",
    "    classifier_instance.auto_handler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
