{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f684eb0-16ee-4532-8f6e-0c9070afedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import tfod\n",
    "import bbox_prep\n",
    "import detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83030f9d-ed01-491f-a4c0-bf1559ad643f",
   "metadata": {},
   "source": [
    "#### Detection Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632db52d-031c-4a69-b240-f5f7a8ec93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to base folder \n",
    "MAIN_FOLDER = pathlib.Path(\"./Main_Folder\")\n",
    "\n",
    "''' Detection Constants '''\n",
    "# Path to label map\n",
    "LABEL_PATH = pathlib.Path(\"./Tensorflow/workspace/training_demo/annotations/label_map.pbtxt\")\n",
    "# Path to pipeline file\n",
    "CONFIG_PATH = pathlib.Path(\"./Tensorflow/workspace/training_demo/models/bbox_efficientdet1_v2/pipeline.config\")\n",
    "# Path to checkpoint file\n",
    "CKPT_PATH = \"./Tensorflow/workspace/training_demo/models/bbox_efficientdet1_v2/ckpt-21\".encode('utf-8')\n",
    "# Path to image folder. Do for pos and neg seperately\n",
    "IMAGE_PATH = MAIN_FOLDER / \"images\"\n",
    "# Path to the csv to save bboxes in\n",
    "BBOX_CSV_NAME = IMAGE_PATH / \"bboxes_ckpt21.csv\"\n",
    "# Resize all images to this before detection. Is set manually to have uniform images\n",
    "PREF_SIZE = (1500, 1500) \n",
    "\n",
    "''' Bbox preperation constants '''\n",
    "CONTRAST_FACTORS = [1.3, 1.5, 1.7]\n",
    "CUT_IMAGE_SIZE = (220, 220)\n",
    "CUT_SAVE_ADDRESS = IMAGE_PATH / \"noCrownCrop\"    # address to save croppped images\n",
    "\n",
    "''' Classification Constants '''\n",
    "# Seperate left and right side images to perform classification on them. Choosing contrast1.5 images is suggested. \n",
    "LEFT_IMAGES_PATH = MAIN_FOLDER / \"left\"            \n",
    "RIGHT_IMAGES_PATH = MAIN_FOLDER / \"right\"\n",
    "MODEL_LOAD_FOLDER = \"model path\"\n",
    "MODEL_ADDRESS = MODEL_LOAD_FOLDER / \"model name\"   # Set the model name\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfb13f-ff64-49e8-883b-019f7ca97185",
   "metadata": {},
   "source": [
    "#### Tensorflow Object Detection, efficientdet_d1_coco17_tpu-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b08d7a-454c-45ed-a54f-6c0b656422d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection of 0 files done, 20 remaining.\n",
      "Detection of 5 files done, 15 remaining.\n",
      "Detection of 10 files done, 10 remaining.\n",
      "BBox Detection of 20 files finished.\n"
     ]
    }
   ],
   "source": [
    "image_list = list(IMAGE_PATH.glob(\"./*.png\"))\n",
    "tfod_instance = tfod.Tfod_User(CONFIG_PATH, CKPT_PATH, LABEL_PATH, image_list, PREF_SIZE, BBOX_CSV_NAME)\n",
    "tfod_instance.model_loader()\n",
    "tfod_instance.detection_batched()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "del tfod_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bd812-a0c8-4c2e-999d-a99cb138c2e2",
   "metadata": {},
   "source": [
    "#### Boundig Box Preparation to cut images and save them in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc3629d-b78e-4730-936c-ea7f2b169e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = list(IMAGE_PATH.glob(\"./*.png\"))\n",
    "if not os.path.isdir(CUT_SAVE_ADDRESS):\n",
    "    os.mkdir(CUT_SAVE_ADDRESS)\n",
    "\n",
    "bbox_instance = bbox_prep.Bbox_User(image_list, BBOX_CSV_NAME, IMAGE_PATH, CUT_SAVE_ADDRESS, CONTRAST_FACTORS, prefix=\"c\", size=CUT_IMAGE_SIZE)\n",
    "bbox_instance.auto_handler()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a766c95-d75f-4ebb-a0b3-50d84f33531b",
   "metadata": {},
   "source": [
    "#### Classification: Predict and save result in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678f7ac-b011-4b89-a1ae-64d05ec5c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_images = list(LEFT_IMAGES_PATH.glob(\"./*.png\"))\n",
    "right_images = list(RIGHT_IMAGES_PATH.glob(\"./*.png\"))\n",
    "if len(left_images):\n",
    "    result_csv_left = \"./Classification Result Left.csv\"\n",
    "    classifier_instance = detector.Model_Handler(MODEL_ADDRESS, left_images, result_csv_left, (220, 220), \"left\", BATCH_SIZE)\n",
    "    classifier_instance.auto_handler()\n",
    "if len(right_images):\n",
    "    result_csv_right = \"./Classification Result Right.csv\"\n",
    "    classifier_instance = detector.Model_Handler(MODEL_ADDRESS, right_images, result_csv_right, (220, 220), \"right\", BATCH_SIZE)\n",
    "    classifier_instance.auto_handler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907ae04-1a66-461d-ab1d-30f085e07e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
