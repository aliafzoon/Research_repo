{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Reshape, Flatten, Conv1D, Dropout, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_FOLDER = pathlib.Path(\"F:\\\\ML\\\\venv3.9\\\\Scripts\\\\Moradzadeh\\\\First_Project\\\\New_Section\")\n",
    "TRAIN_FILE = MAIN_FOLDER / \"data\\\\case1_train.csv\"\n",
    "TEST_FILE = MAIN_FOLDER / \"data\\\\case3_test.csv\"\n",
    "STATS_FILE = MAIN_FOLDER / \"data\\\\x_stats.csv\"\n",
    "MODEL_SAVE_FOLDER = MAIN_FOLDER / \"models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def united_cat(df):\n",
    "    unq_labels = sorted(df[\"Label\"].unique())\n",
    "    label_dict = dict(zip(unq_labels, list(range(len(unq_labels)))))\n",
    "    df.Label = df[\"Label\"].map(label_dict)\n",
    "    return df, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9084, 33)   validation shape: (1600, 33)   Test shape: (10684, 33)\n",
      "Y train shape: (9084, 16)   Y test_shape: (10684, 16)\n"
     ]
    }
   ],
   "source": [
    "# Trainin data\n",
    "train_init_data = pd.read_csv(TRAIN_FILE, index_col=0)\n",
    "train_init_data = shuffle(train_init_data, random_state=7)         # Shuffle\n",
    "train_init_data, train_label_dict = united_cat(train_init_data)    # Rename classes\n",
    "y = train_init_data.pop(\"Label\")\n",
    "y = to_categorical(y)                          # One-hot encoding\n",
    "# Train / Validation split \n",
    "x_train = np.array(train_init_data.iloc[:-1600])\n",
    "x_validation = np.array(train_init_data.iloc[-1600:])\n",
    "y_train = y[:-1600]\n",
    "y_validation = y[-1600:]\n",
    "\n",
    "# Testing data\n",
    "test_init_data = pd.read_csv(TEST_FILE, index_col=0)\n",
    "test_init_data, test_label_dict = united_cat(test_init_data)      # Rename classes \n",
    "y_test = np.array(test_init_data.pop(\"Label\"))\n",
    "y_test = to_categorical(y_test)                 # One-hot encoding\n",
    "x_test = np.array(test_init_data)\n",
    "\n",
    "print(\"train shape:\", x_train.shape, \"  validation shape:\", x_validation.shape, \"  Test shape:\", x_test.shape)\n",
    "print(\"Y train shape:\", y_train.shape, \"  Y test_shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.78900000e+03, -3.92489800e+00, -1.04860120e+01, -8.52980500e+00,\n",
       "       -7.32590300e+00, -1.20769870e+01, -1.12773740e+01, -1.12773740e+01,\n",
       "       -1.27552790e+01, -1.29843500e+01, -1.26968620e+01, -1.30021810e+01,\n",
       "       -1.18292740e+01, -1.40319480e+01,  1.15772164e+02,  5.73265450e+01,\n",
       "        5.78436380e+01,  4.55823490e+01,  3.41377590e+01, -1.99627270e+01,\n",
       "       -4.98980370e+01,  2.34472310e+01,  1.36840170e+01,  3.53036180e+01,\n",
       "        5.43934100e+00,  6.31236700e+00,  4.20120900e+00,  0.00000000e+00,\n",
       "        2.34472310e+01,  4.73142000e+00,  8.24102100e+00, -2.61239100e+00,\n",
       "       -5.34058000e+00,  8.23158900e+00])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stats = pd.read_csv(STATS_FILE, index_col=0)\n",
    "x_norm_layer = tf.keras.layers.experimental.preprocessing.Normalization(mean=x_stats.loc['mean'], variance=x_stats.loc['var'])\n",
    "x_train_norm = x_norm_layer(x_train)\n",
    "x_validation_norm = x_norm_layer(x_validation)\n",
    "x_test_norm = x_norm_layer(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttack:\n",
    "    def __init__(self, model_save_folder, dataset, batch_size=512):\n",
    "        self.input_shape = (33,) \n",
    "        self.model_save_folder = model_save_folder\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.lstm_opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "        self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "        \n",
    "        # Create LSTM\n",
    "        self.lstm = self.build_model()\n",
    "        self.lstm.summary()\n",
    "        \n",
    "        # Define metrics for log\n",
    "        self.train_lstm_loss = tf.keras.metrics.Mean('lstm_training_loss', dtype=tf.float32)\n",
    "        self.train_lstm_accuracy = tf.keras.metrics.CategoricalAccuracy('lstm_training_accuracy', dtype=tf.float32)\n",
    "        self.test_lstm_loss = tf.keras.metrics.Mean('lstm_test_loss', dtype=tf.float32)\n",
    "        self.test_lstm_accuracy= tf.keras.metrics.CategoricalAccuracy('lstm_test_accuracy', dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "    def load_model(self, model_path):\n",
    "        self.lstm = tf.keras.models.load_model(model_path) \n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        input_layer = tf.keras.Input(shape = self.input_shape)\n",
    "        reshaper = Reshape((1, 33))(input_layer)\n",
    "        bi_lstm = Bidirectional(LSTM(22, return_sequences=False))(reshaper)\n",
    "        bi_lstm = Dropout(0.15)(bi_lstm)\n",
    "        dense1 = Flatten()(bi_lstm)\n",
    "        dense1 = Dense(14, activation='tanh')(dense1)\n",
    "        out = Dense(16, activation='softmax', name=\"output\")(dense1)\n",
    "        model_lstm = tf.keras.Model(inputs=input_layer, outputs= [out], name=\"lstm_model\")\n",
    "        return model_lstm\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, one_batch):\n",
    "        x, y = one_batch        \n",
    "        with tf.GradientTape() as tape:\n",
    "            lstm_pred = self.lstm(x)\n",
    "            lstm_loss = self.loss_fn(y, lstm_pred)\n",
    "        grads = tape.gradient(lstm_loss, self.lstm.trainable_weights)\n",
    "        self.lstm_opt.apply_gradients(zip(grads, self.lstm.trainable_weights))\n",
    "        \n",
    "        self.train_lstm_loss.update_state(lstm_loss)\n",
    "        self.train_lstm_accuracy.update_state(y, lstm_pred)\n",
    "        return lstm_loss\n",
    "        \n",
    "        \n",
    "    def test_step(self, one_batch):\n",
    "        x, y = one_batch\n",
    "        lstm_pred = self.lstm.predict(x)\n",
    "        test_loss = self.loss_fn(y, lstm_pred)\n",
    "        \n",
    "        self.test_lstm_loss.update_state(test_loss)\n",
    "        self.test_lstm_accuracy.update_state(y, lstm_pred)\n",
    "        return test_loss\n",
    "    \n",
    "    def train(self, epochs, save_interval=50):\n",
    "        current_time = str(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        log_dir = str(self.model_save_folder) + \"\\\\logs\\\\\" + current_time\n",
    "        summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "        \n",
    "        x_train, y_train, x_test, y_test = self.dataset\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(self.batch_size)\n",
    "        for epoch in range(epochs+1):\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(9000).batch(self.batch_size)\n",
    "            # Training\n",
    "            for step, one_batch in enumerate(train_dataset):\n",
    "                lstm_loss = self.train_step(one_batch)\n",
    "            \n",
    "            # Testing\n",
    "            for step, test_batch in enumerate(test_dataset):\n",
    "                test_loss = self.test_step(test_batch)\n",
    "    \n",
    "            epoch_train_loss = self.train_lstm_loss.result().numpy()\n",
    "            epoch_train_acc = self.train_lstm_accuracy.result().numpy()\n",
    "            epoch_test_loss = self.test_lstm_loss.result().numpy()\n",
    "            epoch_test_acc = self.test_lstm_accuracy.result().numpy()\n",
    "\n",
    "            # Print metrics\n",
    "            print(f\"epoch={epoch}/ train loss={epoch_train_loss:0.4f}\" +\n",
    "                  f\"/ train accuracy={epoch_train_acc:0.4f}\" +\n",
    "                  f\"/ test loss={epoch_test_loss:0.4f}\" +\n",
    "                  f\"/ test accuracy={epoch_test_acc:0.4f}\")\n",
    "\n",
    "            # Tensorboard metrics\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"Train LSTM Loss\", self.train_lstm_loss.result(), step=epoch)\n",
    "                tf.summary.scalar(\"Train LSTM Accuracy\", self.train_lstm_accuracy.result(), step=epoch)\n",
    "                tf.summary.scalar(\"Test LSTM Loss\", self.test_lstm_loss.result(), step=epoch)\n",
    "                tf.summary.scalar(\"Test LSTM Accuracy\", self.test_lstm_accuracy.result(), step=epoch)\n",
    "\n",
    "            self.train_lstm_loss.reset_state()\n",
    "            self.train_lstm_accuracy.reset_state()\n",
    "            self.test_lstm_loss.reset_state()\n",
    "            self.test_lstm_accuracy.reset_state()\n",
    "            \n",
    "            # Save at requested interval\n",
    "            if epoch % save_interval == 0 and epoch != 0:\n",
    "                self.save_models(epoch, epoch_train_loss, epoch_train_acc, epoch_test_acc)\n",
    "\n",
    "    def test(self, new_dataset):\n",
    "        x_new, y_new = new_dataset\n",
    "        current_dataset = tf.data.Dataset.from_tensor_slices((x_new, y_new)).batch(self.batch_size)\n",
    "        for step, new_batch in enumerate(current_dataset):\n",
    "                new_loss = self.test_step(new_batch)\n",
    "\n",
    "        epoch_new_loss = self.test_lstm_loss.result().numpy()\n",
    "        epoch_new_acc = self.test_lstm_accuracy.result().numpy()\n",
    "        print(f\"Your dataset loss: {epoch_new_loss:0.4f}   accuracy:{epoch_new_acc:0.4f}\")\n",
    "        self.test_lstm_loss.reset_state()\n",
    "        self.test_lstm_accuracy.reset_state()\n",
    "\n",
    "\n",
    "    def save_models(self, epoch, train_loss, train_acc, test_acc):\n",
    "        folder_name = self.model_save_folder / (f\"epoch {epoch} \" + str(time.strftime(\"%Y-%m-%d %H %M\")))\n",
    "        if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "\n",
    "        with open(folder_name/f\"lstm summary.txt\", \"w\") as sum_file:\n",
    "            self.lstm.summary(print_fn=lambda x: sum_file.write(x + '\\n'))\n",
    "        self.lstm.save(str(folder_name / (f\"lstm train loss %.3f acc %.3f test acc %0.3f\" % (train_loss, train_acc, test_acc))))\n",
    "    \n",
    "    def change_lr(self, new_rate):\n",
    "        self.lstm_opt.learning_rate.assign(new_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 33)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 33)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 44)                9856      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                630       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 16)                240       \n",
      "=================================================================\n",
      "Total params: 10,726\n",
      "Trainable params: 10,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_save_folder_name = MODEL_SAVE_FOLDER / \"LSTM\" / (\"at \" + str(time.strftime(\"%Y-%m-%d %H %M\")))\n",
    "if not os.path.isdir(lstm_save_folder_name):\n",
    "    os.mkdir(lstm_save_folder_name)\n",
    "    \n",
    "lstm_model = LSTMAttack(lstm_save_folder_name, dataset = (x_train_norm, y_train, x_validation_norm, y_validation), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/ train loss=2.7650/ train accuracy=0.0633/ test loss=2.7344/ test accuracy=0.1944\n",
      "epoch=1/ train loss=2.7061/ train accuracy=0.2035/ test loss=2.6784/ test accuracy=0.2231\n",
      "epoch=2/ train loss=2.6528/ train accuracy=0.2177/ test loss=2.6270/ test accuracy=0.2325\n",
      "epoch=3/ train loss=2.6034/ train accuracy=0.2292/ test loss=2.5770/ test accuracy=0.2519\n",
      "epoch=4/ train loss=2.5553/ train accuracy=0.2583/ test loss=2.5247/ test accuracy=0.2794\n",
      "epoch=5/ train loss=2.5017/ train accuracy=0.2805/ test loss=2.4625/ test accuracy=0.3156\n",
      "epoch=6/ train loss=2.4386/ train accuracy=0.3306/ test loss=2.3906/ test accuracy=0.3744\n",
      "epoch=7/ train loss=2.3639/ train accuracy=0.3804/ test loss=2.3066/ test accuracy=0.4219\n",
      "epoch=8/ train loss=2.2780/ train accuracy=0.4214/ test loss=2.2126/ test accuracy=0.4600\n",
      "epoch=9/ train loss=2.1821/ train accuracy=0.4614/ test loss=2.1073/ test accuracy=0.5069\n",
      "epoch=10/ train loss=2.0760/ train accuracy=0.5063/ test loss=1.9958/ test accuracy=0.5487\n",
      "epoch=11/ train loss=1.9658/ train accuracy=0.5427/ test loss=1.8806/ test accuracy=0.5838\n",
      "epoch=12/ train loss=1.8520/ train accuracy=0.5807/ test loss=1.7632/ test accuracy=0.6231\n",
      "epoch=13/ train loss=1.7374/ train accuracy=0.6238/ test loss=1.6479/ test accuracy=0.6531\n",
      "epoch=14/ train loss=1.6260/ train accuracy=0.6574/ test loss=1.5358/ test accuracy=0.6831\n",
      "epoch=15/ train loss=1.5166/ train accuracy=0.6896/ test loss=1.4273/ test accuracy=0.7113\n",
      "epoch=16/ train loss=1.4123/ train accuracy=0.7174/ test loss=1.3247/ test accuracy=0.7469\n",
      "epoch=17/ train loss=1.3135/ train accuracy=0.7573/ test loss=1.2281/ test accuracy=0.7744\n",
      "epoch=18/ train loss=1.2197/ train accuracy=0.7797/ test loss=1.1383/ test accuracy=0.7900\n",
      "epoch=19/ train loss=1.1336/ train accuracy=0.7932/ test loss=1.0558/ test accuracy=0.7975\n",
      "epoch=20/ train loss=1.0519/ train accuracy=0.8032/ test loss=0.9802/ test accuracy=0.8100\n",
      "epoch=21/ train loss=0.9784/ train accuracy=0.8121/ test loss=0.9109/ test accuracy=0.8225\n",
      "epoch=22/ train loss=0.9108/ train accuracy=0.8246/ test loss=0.8477/ test accuracy=0.8275\n",
      "epoch=23/ train loss=0.8487/ train accuracy=0.8334/ test loss=0.7900/ test accuracy=0.8363\n",
      "epoch=24/ train loss=0.7914/ train accuracy=0.8430/ test loss=0.7371/ test accuracy=0.8469\n",
      "epoch=25/ train loss=0.7384/ train accuracy=0.8507/ test loss=0.6884/ test accuracy=0.8544\n",
      "epoch=26/ train loss=0.6901/ train accuracy=0.8580/ test loss=0.6434/ test accuracy=0.8569\n",
      "epoch=27/ train loss=0.6447/ train accuracy=0.8649/ test loss=0.6033/ test accuracy=0.8594\n",
      "epoch=28/ train loss=0.6047/ train accuracy=0.8690/ test loss=0.5659/ test accuracy=0.8700\n",
      "epoch=29/ train loss=0.5678/ train accuracy=0.8753/ test loss=0.5328/ test accuracy=0.8750\n",
      "epoch=30/ train loss=0.5349/ train accuracy=0.8831/ test loss=0.5018/ test accuracy=0.8838\n",
      "epoch=31/ train loss=0.5047/ train accuracy=0.8904/ test loss=0.4741/ test accuracy=0.8869\n",
      "epoch=32/ train loss=0.4762/ train accuracy=0.8937/ test loss=0.4486/ test accuracy=0.8900\n",
      "epoch=33/ train loss=0.4517/ train accuracy=0.8964/ test loss=0.4254/ test accuracy=0.8938\n",
      "epoch=34/ train loss=0.4285/ train accuracy=0.8985/ test loss=0.4043/ test accuracy=0.8956\n",
      "epoch=35/ train loss=0.4069/ train accuracy=0.9003/ test loss=0.3846/ test accuracy=0.8969\n",
      "epoch=36/ train loss=0.3874/ train accuracy=0.9029/ test loss=0.3665/ test accuracy=0.9031\n",
      "epoch=37/ train loss=0.3693/ train accuracy=0.9102/ test loss=0.3493/ test accuracy=0.9144\n",
      "epoch=38/ train loss=0.3517/ train accuracy=0.9189/ test loss=0.3334/ test accuracy=0.9225\n",
      "epoch=39/ train loss=0.3353/ train accuracy=0.9360/ test loss=0.3179/ test accuracy=0.9463\n",
      "epoch=40/ train loss=0.3195/ train accuracy=0.9441/ test loss=0.3028/ test accuracy=0.9488\n",
      "epoch=41/ train loss=0.3043/ train accuracy=0.9454/ test loss=0.2880/ test accuracy=0.9494\n",
      "epoch=42/ train loss=0.2893/ train accuracy=0.9455/ test loss=0.2741/ test accuracy=0.9494\n",
      "epoch=43/ train loss=0.2753/ train accuracy=0.9455/ test loss=0.2598/ test accuracy=0.9494\n",
      "epoch=44/ train loss=0.2604/ train accuracy=0.9455/ test loss=0.2461/ test accuracy=0.9494\n",
      "epoch=45/ train loss=0.2465/ train accuracy=0.9461/ test loss=0.2326/ test accuracy=0.9500\n",
      "epoch=46/ train loss=0.2326/ train accuracy=0.9516/ test loss=0.2194/ test accuracy=0.9631\n",
      "epoch=47/ train loss=0.2193/ train accuracy=0.9618/ test loss=0.2066/ test accuracy=0.9669\n",
      "epoch=48/ train loss=0.2061/ train accuracy=0.9681/ test loss=0.1946/ test accuracy=0.9744\n",
      "epoch=49/ train loss=0.1941/ train accuracy=0.9750/ test loss=0.1826/ test accuracy=0.9819\n",
      "epoch=50/ train loss=0.1822/ train accuracy=0.9805/ test loss=0.1714/ test accuracy=0.9869\n",
      "epoch=51/ train loss=0.1705/ train accuracy=0.9845/ test loss=0.1609/ test accuracy=0.9894\n",
      "epoch=52/ train loss=0.1601/ train accuracy=0.9868/ test loss=0.1510/ test accuracy=0.9900\n",
      "epoch=53/ train loss=0.1500/ train accuracy=0.9887/ test loss=0.1416/ test accuracy=0.9931\n",
      "epoch=54/ train loss=0.1409/ train accuracy=0.9930/ test loss=0.1331/ test accuracy=0.9956\n",
      "epoch=55/ train loss=0.1320/ train accuracy=0.9953/ test loss=0.1251/ test accuracy=1.0000\n",
      "epoch=56/ train loss=0.1241/ train accuracy=0.9993/ test loss=0.1179/ test accuracy=0.9975\n",
      "epoch=57/ train loss=0.1171/ train accuracy=0.9991/ test loss=0.1109/ test accuracy=1.0000\n",
      "epoch=58/ train loss=0.1102/ train accuracy=0.9994/ test loss=0.1046/ test accuracy=1.0000\n",
      "epoch=59/ train loss=0.1040/ train accuracy=1.0000/ test loss=0.0989/ test accuracy=1.0000\n",
      "epoch=60/ train loss=0.0983/ train accuracy=1.0000/ test loss=0.0935/ test accuracy=1.0000\n",
      "epoch=61/ train loss=0.0929/ train accuracy=1.0000/ test loss=0.0885/ test accuracy=1.0000\n",
      "epoch=62/ train loss=0.0881/ train accuracy=1.0000/ test loss=0.0840/ test accuracy=1.0000\n",
      "epoch=63/ train loss=0.0837/ train accuracy=1.0000/ test loss=0.0799/ test accuracy=1.0000\n",
      "epoch=64/ train loss=0.0795/ train accuracy=1.0000/ test loss=0.0759/ test accuracy=1.0000\n",
      "epoch=65/ train loss=0.0757/ train accuracy=1.0000/ test loss=0.0724/ test accuracy=1.0000\n",
      "epoch=66/ train loss=0.0721/ train accuracy=1.0000/ test loss=0.0691/ test accuracy=1.0000\n",
      "epoch=67/ train loss=0.0688/ train accuracy=1.0000/ test loss=0.0660/ test accuracy=1.0000\n",
      "epoch=68/ train loss=0.0659/ train accuracy=1.0000/ test loss=0.0632/ test accuracy=1.0000\n",
      "epoch=69/ train loss=0.0629/ train accuracy=1.0000/ test loss=0.0604/ test accuracy=1.0000\n",
      "epoch=70/ train loss=0.0603/ train accuracy=1.0000/ test loss=0.0580/ test accuracy=1.0000\n",
      "epoch=71/ train loss=0.0578/ train accuracy=1.0000/ test loss=0.0556/ test accuracy=1.0000\n",
      "epoch=72/ train loss=0.0555/ train accuracy=1.0000/ test loss=0.0534/ test accuracy=1.0000\n",
      "epoch=73/ train loss=0.0533/ train accuracy=1.0000/ test loss=0.0513/ test accuracy=1.0000\n",
      "epoch=74/ train loss=0.0512/ train accuracy=1.0000/ test loss=0.0493/ test accuracy=1.0000\n",
      "epoch=75/ train loss=0.0493/ train accuracy=1.0000/ test loss=0.0475/ test accuracy=1.0000\n",
      "epoch=76/ train loss=0.0475/ train accuracy=1.0000/ test loss=0.0458/ test accuracy=1.0000\n",
      "epoch=77/ train loss=0.0458/ train accuracy=1.0000/ test loss=0.0442/ test accuracy=1.0000\n",
      "epoch=78/ train loss=0.0442/ train accuracy=1.0000/ test loss=0.0426/ test accuracy=1.0000\n",
      "epoch=79/ train loss=0.0427/ train accuracy=1.0000/ test loss=0.0412/ test accuracy=1.0000\n",
      "epoch=80/ train loss=0.0412/ train accuracy=1.0000/ test loss=0.0398/ test accuracy=1.0000\n",
      "epoch=81/ train loss=0.0398/ train accuracy=1.0000/ test loss=0.0385/ test accuracy=1.0000\n",
      "epoch=82/ train loss=0.0385/ train accuracy=1.0000/ test loss=0.0373/ test accuracy=1.0000\n",
      "epoch=83/ train loss=0.0374/ train accuracy=1.0000/ test loss=0.0361/ test accuracy=1.0000\n",
      "epoch=84/ train loss=0.0361/ train accuracy=1.0000/ test loss=0.0350/ test accuracy=1.0000\n",
      "epoch=85/ train loss=0.0350/ train accuracy=1.0000/ test loss=0.0339/ test accuracy=1.0000\n",
      "epoch=86/ train loss=0.0340/ train accuracy=1.0000/ test loss=0.0329/ test accuracy=1.0000\n",
      "epoch=87/ train loss=0.0330/ train accuracy=1.0000/ test loss=0.0319/ test accuracy=1.0000\n",
      "epoch=88/ train loss=0.0320/ train accuracy=1.0000/ test loss=0.0310/ test accuracy=1.0000\n",
      "epoch=89/ train loss=0.0311/ train accuracy=1.0000/ test loss=0.0301/ test accuracy=1.0000\n",
      "epoch=90/ train loss=0.0302/ train accuracy=1.0000/ test loss=0.0293/ test accuracy=1.0000\n",
      "epoch=91/ train loss=0.0293/ train accuracy=1.0000/ test loss=0.0285/ test accuracy=1.0000\n",
      "epoch=92/ train loss=0.0286/ train accuracy=1.0000/ test loss=0.0277/ test accuracy=1.0000\n",
      "epoch=93/ train loss=0.0278/ train accuracy=1.0000/ test loss=0.0270/ test accuracy=1.0000\n",
      "epoch=94/ train loss=0.0271/ train accuracy=1.0000/ test loss=0.0263/ test accuracy=1.0000\n",
      "epoch=95/ train loss=0.0263/ train accuracy=1.0000/ test loss=0.0256/ test accuracy=1.0000\n",
      "epoch=96/ train loss=0.0256/ train accuracy=1.0000/ test loss=0.0249/ test accuracy=1.0000\n",
      "epoch=97/ train loss=0.0250/ train accuracy=1.0000/ test loss=0.0243/ test accuracy=1.0000\n",
      "epoch=98/ train loss=0.0243/ train accuracy=1.0000/ test loss=0.0237/ test accuracy=1.0000\n",
      "epoch=99/ train loss=0.0237/ train accuracy=1.0000/ test loss=0.0231/ test accuracy=1.0000\n",
      "epoch=100/ train loss=0.0232/ train accuracy=1.0000/ test loss=0.0225/ test accuracy=1.0000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: F:\\ML\\venv3.9\\Scripts\\Moradzadeh\\First_Project\\New_Section\\models\\LSTM\\at 2022-02-04 02 35\\epoch 100 2022-02-04 02 37\\lstm train loss 0.023 acc 1.000 test acc 1.000\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: F:\\ML\\venv3.9\\Scripts\\Moradzadeh\\First_Project\\New_Section\\models\\LSTM\\at 2022-02-04 02 35\\epoch 100 2022-02-04 02 37\\lstm train loss 0.023 acc 1.000 test acc 1.000\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_model.train(100, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset loss: 0.0949   accuracy:0.9800\n"
     ]
    }
   ],
   "source": [
    "lstm_model.test((x_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l24  d0.15  dense14 96.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAttack:\n",
    "    def __init__(self, model_save_folder, dataset, batch_size=512):\n",
    "        self.input_shape = (33,) \n",
    "        self.model_save_folder = model_save_folder\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.cnn_opt = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "        self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "        \n",
    "        # Create CNN\n",
    "        self.cnn = self.build_model()\n",
    "        self.cnn.summary()\n",
    "        \n",
    "        # Define metrics for log\n",
    "        self.train_cnn_loss = tf.keras.metrics.Mean('cnn_training_loss', dtype=tf.float32)\n",
    "        self.train_cnn_accuracy = tf.keras.metrics.CategoricalAccuracy('cnn_training_accuracy', dtype=tf.float32)\n",
    "        self.test_cnn_loss = tf.keras.metrics.Mean('cnn_test_loss', dtype=tf.float32)\n",
    "        self.test_cnn_accuracy= tf.keras.metrics.CategoricalAccuracy('cnn_test_accuracy', dtype=tf.float32)\n",
    "        \n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.cnn = tf.keras.models.load_model(model_path) \n",
    "        \n",
    "    def build_model(self):\n",
    "        input_layer = tf.keras.Input(shape = self.input_shape)\n",
    "        reshaper = Reshape((33, 1))(input_layer)\n",
    "        cnn = Conv1D(16, kernel_size=3, strides=1, padding='same', activation='tanh')(reshaper)\n",
    "        #bi_lstm = Activation(\"tanh\")\n",
    "        cnn = Dropout(0.15)(cnn)\n",
    "        dense1 = Flatten()(cnn)\n",
    "        dense1 = Dense(14, activation='tanh')(dense1)\n",
    "        out = Dense(16, activation='softmax', name=\"output\")(dense1)\n",
    "        model_cnn = tf.keras.Model(inputs=input_layer, outputs= [out], name=\"cnn_model\")\n",
    "        return model_cnn\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, one_batch):\n",
    "        x, y = one_batch        \n",
    "        with tf.GradientTape() as tape:\n",
    "            cnn_pred = self.cnn(x)\n",
    "            cnn_loss = self.loss_fn(y, cnn_pred)\n",
    "        grads = tape.gradient(cnn_loss, self.cnn.trainable_weights)\n",
    "        self.cnn_opt.apply_gradients(zip(grads, self.cnn.trainable_weights))\n",
    "        \n",
    "        self.train_cnn_loss.update_state(cnn_loss)\n",
    "        self.train_cnn_accuracy.update_state(y, cnn_pred)\n",
    "        return cnn_loss\n",
    "        \n",
    "        \n",
    "    def test_step(self, one_batch):\n",
    "        x, y = one_batch\n",
    "        cnn_pred = self.cnn.predict(x)\n",
    "        test_loss = self.loss_fn(y, cnn_pred)\n",
    "        \n",
    "        self.test_cnn_loss.update_state(test_loss)\n",
    "        self.test_cnn_accuracy.update_state(y, cnn_pred)\n",
    "        return test_loss\n",
    "    \n",
    "    def train(self, epochs, save_interval=50):\n",
    "        current_time = str(time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        log_dir = str(self.model_save_folder) + \"\\\\logs\\\\\" + current_time\n",
    "        summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "        \n",
    "        x_train, y_train, x_test, y_test = self.dataset\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(self.batch_size)\n",
    "        for epoch in range(epochs+1):\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(9000).batch(self.batch_size)\n",
    "            # Training\n",
    "            for step, one_batch in enumerate(train_dataset):\n",
    "                cnn_loss = self.train_step(one_batch)\n",
    "            \n",
    "            # Testing\n",
    "            for step, test_batch in enumerate(test_dataset):\n",
    "                test_loss = self.test_step(test_batch)\n",
    "    \n",
    "            epoch_train_loss = self.train_cnn_loss.result().numpy()\n",
    "            epoch_train_acc = self.train_cnn_accuracy.result().numpy()\n",
    "            epoch_test_loss = self.test_cnn_loss.result().numpy()\n",
    "            epoch_test_acc = self.test_cnn_accuracy.result().numpy()\n",
    "\n",
    "            # Print metrics\n",
    "            print(f\"epoch={epoch}/ train loss={epoch_train_loss:0.4f}\" +\n",
    "                  f\"/ train accuracy={epoch_train_acc:0.4f}\" +\n",
    "                  f\"/ test loss={epoch_test_loss:0.4f}\" +\n",
    "                  f\"/ test accuracy={epoch_test_acc:0.4f}\")\n",
    "\n",
    "            # Tensorboard metrics\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar(\"Train cnn Loss\", self.train_cnn_loss.result(), step=epoch)\n",
    "                tf.summary.scalar(\"Train cnn Accuracy\", self.train_cnn_accuracy.result(), step=epoch)\n",
    "                tf.summary.scalar(\"Test cnn Loss\", self.test_cnn_loss.result(), step=epoch)\n",
    "                tf.summary.scalar(\"Test cnn Accuracy\", self.test_cnn_accuracy.result(), step=epoch)\n",
    "\n",
    "            self.train_cnn_loss.reset_state()\n",
    "            self.train_cnn_accuracy.reset_state()\n",
    "            self.test_cnn_loss.reset_state()\n",
    "            self.test_cnn_accuracy.reset_state()\n",
    "            \n",
    "            # Save at requested interval\n",
    "            if epoch % save_interval == 0 and epoch != 0:\n",
    "                self.save_models(epoch, epoch_train_loss, epoch_train_acc, epoch_test_acc)\n",
    "\n",
    "    def test(self, new_dataset):\n",
    "        x_new, y_new = new_dataset\n",
    "        current_dataset = tf.data.Dataset.from_tensor_slices((x_new, y_new)).batch(self.batch_size)\n",
    "        for step, new_batch in enumerate(current_dataset):\n",
    "                new_loss = self.test_step(new_batch)\n",
    "\n",
    "        epoch_new_loss = self.test_cnn_loss.result().numpy()\n",
    "        epoch_new_acc = self.test_cnn_accuracy.result().numpy()\n",
    "        print(f\"Your dataset loss: {epoch_new_loss:0.4f}   accuracy:{epoch_new_acc:0.4f}\")\n",
    "        self.test_cnn_loss.reset_state()\n",
    "        self.test_cnn_accuracy.reset_state()\n",
    "\n",
    "\n",
    "    def save_models(self, epoch, train_loss, train_acc, test_acc):\n",
    "        folder_name = self.model_save_folder / (f\"epoch {epoch} \" + str(time.strftime(\"%Y-%m-%d %H %M\")))\n",
    "        if not os.path.isdir(folder_name):\n",
    "            os.mkdir(folder_name)\n",
    "\n",
    "        with open(folder_name/f\"cnn summary.txt\", \"w\") as sum_file:\n",
    "            self.cnn.summary(print_fn=lambda x: sum_file.write(x + '\\n'))\n",
    "        self.cnn.save(str(folder_name / (f\"cnn train loss %.3f acc %.3f test acc %0.3f\" % (train_loss, train_acc, test_acc))))\n",
    "    \n",
    "    def change_lr(self, new_rate):\n",
    "        self.cnn_opt.learning_rate.assign(new_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 33)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 33, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 33, 16)            64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 528)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                7406      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 16)                240       \n",
      "=================================================================\n",
      "Total params: 7,710\n",
      "Trainable params: 7,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_save_folder_name = MODEL_SAVE_FOLDER / \"CNN\" / (\"at \" + str(time.strftime(\"%Y-%m-%d %H %M\")))\n",
    "if not os.path.isdir(cnn_save_folder_name):\n",
    "    os.mkdir(cnn_save_folder_name)\n",
    "    \n",
    "cnn_model = CNNAttack(cnn_save_folder_name, dataset = (x_train_norm, y_train, x_validation_norm, y_validation), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0/ train loss=0.1371/ train accuracy=0.9732/ test loss=0.1323/ test accuracy=0.9719\n",
      "epoch=1/ train loss=0.1358/ train accuracy=0.9732/ test loss=0.1314/ test accuracy=0.9719\n",
      "epoch=2/ train loss=0.1352/ train accuracy=0.9732/ test loss=0.1303/ test accuracy=0.9719\n",
      "epoch=3/ train loss=0.1341/ train accuracy=0.9732/ test loss=0.1294/ test accuracy=0.9719\n",
      "epoch=4/ train loss=0.1334/ train accuracy=0.9732/ test loss=0.1286/ test accuracy=0.9719\n",
      "epoch=5/ train loss=0.1323/ train accuracy=0.9732/ test loss=0.1276/ test accuracy=0.9719\n",
      "epoch=6/ train loss=0.1312/ train accuracy=0.9732/ test loss=0.1267/ test accuracy=0.9719\n",
      "epoch=7/ train loss=0.1305/ train accuracy=0.9732/ test loss=0.1259/ test accuracy=0.9719\n",
      "epoch=8/ train loss=0.1296/ train accuracy=0.9732/ test loss=0.1250/ test accuracy=0.9719\n",
      "epoch=9/ train loss=0.1286/ train accuracy=0.9732/ test loss=0.1241/ test accuracy=0.9719\n",
      "epoch=10/ train loss=0.1279/ train accuracy=0.9732/ test loss=0.1233/ test accuracy=0.9719\n",
      "epoch=11/ train loss=0.1269/ train accuracy=0.9732/ test loss=0.1225/ test accuracy=0.9719\n",
      "epoch=12/ train loss=0.1261/ train accuracy=0.9732/ test loss=0.1216/ test accuracy=0.9719\n",
      "epoch=13/ train loss=0.1252/ train accuracy=0.9732/ test loss=0.1209/ test accuracy=0.9719\n",
      "epoch=14/ train loss=0.1246/ train accuracy=0.9732/ test loss=0.1200/ test accuracy=0.9719\n",
      "epoch=15/ train loss=0.1234/ train accuracy=0.9732/ test loss=0.1192/ test accuracy=0.9719\n",
      "epoch=16/ train loss=0.1226/ train accuracy=0.9730/ test loss=0.1184/ test accuracy=0.9719\n",
      "epoch=17/ train loss=0.1219/ train accuracy=0.9732/ test loss=0.1177/ test accuracy=0.9719\n",
      "epoch=18/ train loss=0.1211/ train accuracy=0.9732/ test loss=0.1168/ test accuracy=0.9719\n",
      "epoch=19/ train loss=0.1201/ train accuracy=0.9732/ test loss=0.1161/ test accuracy=0.9719\n",
      "epoch=20/ train loss=0.1196/ train accuracy=0.9732/ test loss=0.1154/ test accuracy=0.9719\n",
      "epoch=21/ train loss=0.1191/ train accuracy=0.9732/ test loss=0.1145/ test accuracy=0.9719\n",
      "epoch=22/ train loss=0.1178/ train accuracy=0.9731/ test loss=0.1139/ test accuracy=0.9719\n",
      "epoch=23/ train loss=0.1171/ train accuracy=0.9732/ test loss=0.1131/ test accuracy=0.9719\n",
      "epoch=24/ train loss=0.1164/ train accuracy=0.9732/ test loss=0.1124/ test accuracy=0.9719\n",
      "epoch=25/ train loss=0.1156/ train accuracy=0.9732/ test loss=0.1117/ test accuracy=0.9719\n",
      "epoch=26/ train loss=0.1149/ train accuracy=0.9732/ test loss=0.1109/ test accuracy=0.9719\n",
      "epoch=27/ train loss=0.1141/ train accuracy=0.9732/ test loss=0.1103/ test accuracy=0.9719\n",
      "epoch=28/ train loss=0.1138/ train accuracy=0.9732/ test loss=0.1095/ test accuracy=0.9719\n",
      "epoch=29/ train loss=0.1130/ train accuracy=0.9732/ test loss=0.1089/ test accuracy=0.9719\n",
      "epoch=30/ train loss=0.1121/ train accuracy=0.9732/ test loss=0.1082/ test accuracy=0.9719\n",
      "epoch=31/ train loss=0.1114/ train accuracy=0.9732/ test loss=0.1075/ test accuracy=0.9719\n",
      "epoch=32/ train loss=0.1107/ train accuracy=0.9732/ test loss=0.1068/ test accuracy=0.9719\n",
      "epoch=33/ train loss=0.1100/ train accuracy=0.9732/ test loss=0.1061/ test accuracy=0.9719\n",
      "epoch=34/ train loss=0.1092/ train accuracy=0.9732/ test loss=0.1055/ test accuracy=0.9719\n",
      "epoch=35/ train loss=0.1088/ train accuracy=0.9732/ test loss=0.1048/ test accuracy=0.9719\n",
      "epoch=36/ train loss=0.1079/ train accuracy=0.9732/ test loss=0.1042/ test accuracy=0.9719\n",
      "epoch=37/ train loss=0.1075/ train accuracy=0.9732/ test loss=0.1035/ test accuracy=0.9719\n",
      "epoch=38/ train loss=0.1066/ train accuracy=0.9731/ test loss=0.1028/ test accuracy=0.9719\n",
      "epoch=39/ train loss=0.1059/ train accuracy=0.9732/ test loss=0.1022/ test accuracy=0.9719\n",
      "epoch=40/ train loss=0.1055/ train accuracy=0.9732/ test loss=0.1017/ test accuracy=0.9719\n",
      "epoch=41/ train loss=0.1045/ train accuracy=0.9732/ test loss=0.1011/ test accuracy=0.9719\n",
      "epoch=42/ train loss=0.1041/ train accuracy=0.9732/ test loss=0.1004/ test accuracy=0.9719\n",
      "epoch=43/ train loss=0.1034/ train accuracy=0.9732/ test loss=0.0998/ test accuracy=0.9719\n",
      "epoch=44/ train loss=0.1027/ train accuracy=0.9732/ test loss=0.0993/ test accuracy=0.9719\n",
      "epoch=45/ train loss=0.1022/ train accuracy=0.9732/ test loss=0.0986/ test accuracy=0.9719\n",
      "epoch=46/ train loss=0.1017/ train accuracy=0.9732/ test loss=0.0981/ test accuracy=0.9719\n",
      "epoch=47/ train loss=0.1010/ train accuracy=0.9732/ test loss=0.0975/ test accuracy=0.9719\n",
      "epoch=48/ train loss=0.1003/ train accuracy=0.9732/ test loss=0.0969/ test accuracy=0.9719\n",
      "epoch=49/ train loss=0.0999/ train accuracy=0.9732/ test loss=0.0963/ test accuracy=0.9719\n",
      "epoch=50/ train loss=0.0993/ train accuracy=0.9732/ test loss=0.0958/ test accuracy=0.9719\n",
      "epoch=51/ train loss=0.0985/ train accuracy=0.9732/ test loss=0.0952/ test accuracy=0.9719\n",
      "epoch=52/ train loss=0.0982/ train accuracy=0.9732/ test loss=0.0946/ test accuracy=0.9719\n",
      "epoch=53/ train loss=0.0976/ train accuracy=0.9732/ test loss=0.0941/ test accuracy=0.9719\n",
      "epoch=54/ train loss=0.0969/ train accuracy=0.9732/ test loss=0.0937/ test accuracy=0.9719\n",
      "epoch=55/ train loss=0.0964/ train accuracy=0.9732/ test loss=0.0931/ test accuracy=0.9719\n",
      "epoch=56/ train loss=0.0959/ train accuracy=0.9732/ test loss=0.0926/ test accuracy=0.9719\n",
      "epoch=57/ train loss=0.0953/ train accuracy=0.9732/ test loss=0.0921/ test accuracy=0.9719\n",
      "epoch=58/ train loss=0.0947/ train accuracy=0.9732/ test loss=0.0914/ test accuracy=0.9719\n",
      "epoch=59/ train loss=0.0941/ train accuracy=0.9731/ test loss=0.0909/ test accuracy=0.9719\n",
      "epoch=60/ train loss=0.0936/ train accuracy=0.9732/ test loss=0.0904/ test accuracy=0.9719\n",
      "epoch=61/ train loss=0.0931/ train accuracy=0.9732/ test loss=0.0900/ test accuracy=0.9719\n",
      "epoch=62/ train loss=0.0926/ train accuracy=0.9732/ test loss=0.0894/ test accuracy=0.9719\n",
      "epoch=63/ train loss=0.0921/ train accuracy=0.9732/ test loss=0.0888/ test accuracy=0.9719\n",
      "epoch=64/ train loss=0.0913/ train accuracy=0.9732/ test loss=0.0883/ test accuracy=0.9719\n",
      "epoch=65/ train loss=0.0910/ train accuracy=0.9732/ test loss=0.0878/ test accuracy=0.9719\n",
      "epoch=66/ train loss=0.0903/ train accuracy=0.9732/ test loss=0.0873/ test accuracy=0.9719\n",
      "epoch=67/ train loss=0.0899/ train accuracy=0.9705/ test loss=0.0867/ test accuracy=0.9700\n",
      "epoch=68/ train loss=0.0896/ train accuracy=0.9727/ test loss=0.0862/ test accuracy=0.9719\n",
      "epoch=69/ train loss=0.0888/ train accuracy=0.9732/ test loss=0.0859/ test accuracy=0.9719\n",
      "epoch=70/ train loss=0.0883/ train accuracy=0.9732/ test loss=0.0853/ test accuracy=0.9719\n",
      "epoch=71/ train loss=0.0880/ train accuracy=0.9687/ test loss=0.0848/ test accuracy=0.9638\n",
      "epoch=72/ train loss=0.0874/ train accuracy=0.9728/ test loss=0.0844/ test accuracy=0.9719\n",
      "epoch=73/ train loss=0.0867/ train accuracy=0.9732/ test loss=0.0840/ test accuracy=0.9719\n",
      "epoch=74/ train loss=0.0862/ train accuracy=0.9732/ test loss=0.0835/ test accuracy=0.9719\n",
      "epoch=75/ train loss=0.0859/ train accuracy=0.9732/ test loss=0.0831/ test accuracy=0.9719\n",
      "epoch=76/ train loss=0.0854/ train accuracy=0.9732/ test loss=0.0826/ test accuracy=0.9719\n",
      "epoch=77/ train loss=0.0852/ train accuracy=0.9732/ test loss=0.0822/ test accuracy=0.9719\n",
      "epoch=78/ train loss=0.0848/ train accuracy=0.9732/ test loss=0.0817/ test accuracy=0.9719\n",
      "epoch=79/ train loss=0.0840/ train accuracy=0.9732/ test loss=0.0813/ test accuracy=0.9719\n",
      "epoch=80/ train loss=0.0837/ train accuracy=0.9732/ test loss=0.0808/ test accuracy=0.9719\n",
      "epoch=81/ train loss=0.0833/ train accuracy=0.9732/ test loss=0.0804/ test accuracy=0.9719\n",
      "epoch=82/ train loss=0.0829/ train accuracy=0.9732/ test loss=0.0800/ test accuracy=0.9719\n",
      "epoch=83/ train loss=0.0823/ train accuracy=0.9732/ test loss=0.0796/ test accuracy=0.9719\n",
      "epoch=84/ train loss=0.0821/ train accuracy=0.9732/ test loss=0.0792/ test accuracy=0.9719\n",
      "epoch=85/ train loss=0.0819/ train accuracy=0.9732/ test loss=0.0788/ test accuracy=0.9719\n",
      "epoch=86/ train loss=0.0810/ train accuracy=0.9732/ test loss=0.0784/ test accuracy=0.9719\n",
      "epoch=87/ train loss=0.0808/ train accuracy=0.9732/ test loss=0.0780/ test accuracy=0.9719\n",
      "epoch=88/ train loss=0.0804/ train accuracy=0.9732/ test loss=0.0777/ test accuracy=0.9719\n",
      "epoch=89/ train loss=0.0801/ train accuracy=0.9732/ test loss=0.0772/ test accuracy=0.9719\n",
      "epoch=90/ train loss=0.0795/ train accuracy=0.9732/ test loss=0.0769/ test accuracy=0.9719\n",
      "epoch=91/ train loss=0.0790/ train accuracy=0.9732/ test loss=0.0765/ test accuracy=0.9719\n",
      "epoch=92/ train loss=0.0789/ train accuracy=0.9732/ test loss=0.0761/ test accuracy=0.9719\n",
      "epoch=93/ train loss=0.0785/ train accuracy=0.9732/ test loss=0.0758/ test accuracy=0.9719\n",
      "epoch=94/ train loss=0.0780/ train accuracy=0.9732/ test loss=0.0754/ test accuracy=0.9719\n",
      "epoch=95/ train loss=0.0777/ train accuracy=0.9732/ test loss=0.0750/ test accuracy=0.9719\n",
      "epoch=96/ train loss=0.0773/ train accuracy=0.9731/ test loss=0.0746/ test accuracy=0.9719\n",
      "epoch=97/ train loss=0.0771/ train accuracy=0.9732/ test loss=0.0743/ test accuracy=0.9719\n",
      "epoch=98/ train loss=0.0767/ train accuracy=0.9732/ test loss=0.0740/ test accuracy=0.9719\n",
      "epoch=99/ train loss=0.0761/ train accuracy=0.9732/ test loss=0.0735/ test accuracy=0.9719\n",
      "epoch=100/ train loss=0.0761/ train accuracy=0.9732/ test loss=0.0732/ test accuracy=0.9719\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: F:\\ML\\venv3.9\\Scripts\\Moradzadeh\\First_Project\\New_Section\\models\\CNN\\at 2022-02-04 03 33\\epoch 100 2022-02-04 03 45\\cnn train loss 0.076 acc 0.973 test acc 0.972\\assets\n"
     ]
    }
   ],
   "source": [
    "cnn_model.train(100, save_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset loss: 0.1592   accuracy:0.9847\n"
     ]
    }
   ],
   "source": [
    "cnn_model.test((x_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "cnn_model.load_model(\"F:\\\\ML\\\\venv3.9\\\\Scripts\\\\Moradzadeh\\\\First_Project\\\\New_Section\\\\models\\CNN\\\\at 2022-02-04 03 10\\\\epoch 100 2022-02-04 03 13\\\\cnn train loss 0.097 acc 1.000 test acc 1.000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c16 d10 dense14     98.47  first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_PATH = MODEL_SAVE_FOLDER / \"best\\\\epoch 100 2022-02-04 03 13 best acc 98.47\\\\cnn train loss 0.097 acc 1.000 test acc 1.000\"\n",
    "LSTM_PATH = MODEL_SAVE_FOLDER / \"best\\\\epoch 100 2022-02-04 02 37 best acc 98\\\\lstm train loss 0.023 acc 1.000 test acc 1.000\"\n",
    "acc_metric = tf.keras.metrics.CategoricalAccuracy('accuracy', dtype=tf.float32)\n",
    "reverse_label = {v: k for k, v in test_label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cnn = tf.keras.models.load_model(CNN_PATH)\n",
    "cnn_out = test_cnn.predict(x_test_norm)\n",
    "acc_metric.update_state(y_test, cnn_out)\n",
    "cnn_acc = acc_metric.result().numpy()\n",
    "print(cnn_acc)\n",
    "cnn_pd = pd.DataFrame(columns=[\"predicted\", \"real\"])\n",
    "cnn_pd[\"predicted\"] = np.argmax(cnn_out, axis=1).transpose()\n",
    "cnn_pd[\"real\"] = np.argmax(y_test, axis=1).transpose()\n",
    "cnn_pd[\"real\"], cnn_pd[\"predicted\"] = cnn_pd[\"real\"].map(reverse_label), cnn_pd[\"predicted\"].map(reverse_label)\n",
    "cnn_pd =pd.concat([cnn_pd, test_init_data], axis=1)\n",
    "cnn_pd.to_csv(MODEL_SAVE_FOLDER / \"final_cnn_output.csv\")\n",
    "acc_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "0.97997004\n"
     ]
    }
   ],
   "source": [
    "test_lstm = tf.keras.models.load_model(LSTM_PATH)\n",
    "lstm_out = test_lstm.predict(x_test_norm)\n",
    "acc_metric.update_state(y_test, lstm_out)\n",
    "lstm_acc = acc_metric.result().numpy()\n",
    "print(lstm_acc)\n",
    "lstm_pd = pd.DataFrame(columns=[\"predicted\", \"real\"])\n",
    "lstm_pd[\"predicted\"] = np.argmax(lstm_out, axis=1).transpose()\n",
    "lstm_pd[\"real\"] = np.argmax(y_test, axis=1).transpose()\n",
    "lstm_pd[\"real\"], lstm_pd[\"predicted\"] = lstm_pd[\"real\"].map(reverse_label), lstm_pd[\"predicted\"].map(reverse_label)\n",
    "lstm_pd =pd.concat([lstm_pd, test_init_data], axis=1)\n",
    "lstm_pd.to_csv(MODEL_SAVE_FOLDER / \"final_lstm_output.csv\")\n",
    "acc_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_FOLDER = pathlib.Path(\"F:\\\\ML\\\\venv3.9\\\\Scripts\\\\Moradzadeh\\\\First_Project\\\\New_Section\")\n",
    "TRAIN_FILE = MAIN_FOLDER / \"data\\\\CaseI-Attacks without any change.csv\"\n",
    "TEST_FILE = MAIN_FOLDER / \"data\\\\CaseIII-Attacks after DG integration.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Angle2, Angle3, Angle4, Angle5, Angle6, Angle7, Angle8, Angle9, Angle10, Angle11, Angle12, Angle13, Angle14, Branch1, Branch2, Branch3, Branch4, Branch5, Branch6, Branch7, Branch8, Branch9, Branch10, Branch11, Branch12, Branch13, Branch14, Branch15, Branch16, Branch17, Branch18, Branch19, Branch20, Label]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 34 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angle2</th>\n",
       "      <th>Angle3</th>\n",
       "      <th>Angle4</th>\n",
       "      <th>Angle5</th>\n",
       "      <th>Angle6</th>\n",
       "      <th>Angle7</th>\n",
       "      <th>Angle8</th>\n",
       "      <th>Angle9</th>\n",
       "      <th>Angle10</th>\n",
       "      <th>Angle11</th>\n",
       "      <th>...</th>\n",
       "      <th>Branch12</th>\n",
       "      <th>Branch13</th>\n",
       "      <th>Branch14</th>\n",
       "      <th>Branch15</th>\n",
       "      <th>Branch16</th>\n",
       "      <th>Branch17</th>\n",
       "      <th>Branch18</th>\n",
       "      <th>Branch19</th>\n",
       "      <th>Branch20</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>1.068400e+04</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.644671</td>\n",
       "      <td>-9.885094</td>\n",
       "      <td>-7.986397</td>\n",
       "      <td>-6.860374</td>\n",
       "      <td>-11.350325</td>\n",
       "      <td>-10.551820</td>\n",
       "      <td>-10.551820</td>\n",
       "      <td>-11.931749</td>\n",
       "      <td>-12.164337</td>\n",
       "      <td>-11.907007</td>\n",
       "      <td>...</td>\n",
       "      <td>6.103789</td>\n",
       "      <td>13.862711</td>\n",
       "      <td>-3.657806e-07</td>\n",
       "      <td>21.892834</td>\n",
       "      <td>4.804057</td>\n",
       "      <td>8.078886</td>\n",
       "      <td>-2.338343</td>\n",
       "      <td>1.223160</td>\n",
       "      <td>4.003366</td>\n",
       "      <td>10.242044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.522680</td>\n",
       "      <td>1.167194</td>\n",
       "      <td>0.975713</td>\n",
       "      <td>0.852689</td>\n",
       "      <td>1.292482</td>\n",
       "      <td>1.275340</td>\n",
       "      <td>1.251084</td>\n",
       "      <td>1.427203</td>\n",
       "      <td>1.416860</td>\n",
       "      <td>1.371840</td>\n",
       "      <td>...</td>\n",
       "      <td>1.633094</td>\n",
       "      <td>3.198992</td>\n",
       "      <td>2.434109e+00</td>\n",
       "      <td>5.329356</td>\n",
       "      <td>5.791752</td>\n",
       "      <td>1.935667</td>\n",
       "      <td>2.119438</td>\n",
       "      <td>2.048785</td>\n",
       "      <td>1.339676</td>\n",
       "      <td>13.294249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.935881</td>\n",
       "      <td>-12.809498</td>\n",
       "      <td>-10.437004</td>\n",
       "      <td>-8.957523</td>\n",
       "      <td>-14.576502</td>\n",
       "      <td>-13.703503</td>\n",
       "      <td>-13.703503</td>\n",
       "      <td>-15.460537</td>\n",
       "      <td>-15.720765</td>\n",
       "      <td>-15.354577</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130133</td>\n",
       "      <td>4.089672</td>\n",
       "      <td>-7.042618e+00</td>\n",
       "      <td>9.431774</td>\n",
       "      <td>-11.918270</td>\n",
       "      <td>2.808237</td>\n",
       "      <td>-10.444071</td>\n",
       "      <td>-5.988031</td>\n",
       "      <td>-0.099512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.034503</td>\n",
       "      <td>-10.803379</td>\n",
       "      <td>-8.684925</td>\n",
       "      <td>-7.472805</td>\n",
       "      <td>-12.288738</td>\n",
       "      <td>-11.463168</td>\n",
       "      <td>-11.438667</td>\n",
       "      <td>-12.937993</td>\n",
       "      <td>-13.179128</td>\n",
       "      <td>-12.893056</td>\n",
       "      <td>...</td>\n",
       "      <td>5.507815</td>\n",
       "      <td>12.777745</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19.060383</td>\n",
       "      <td>4.402054</td>\n",
       "      <td>7.426043</td>\n",
       "      <td>-2.612391</td>\n",
       "      <td>1.065833</td>\n",
       "      <td>3.382496</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.751080</td>\n",
       "      <td>-10.125673</td>\n",
       "      <td>-8.212203</td>\n",
       "      <td>-7.032201</td>\n",
       "      <td>-11.620262</td>\n",
       "      <td>-10.796308</td>\n",
       "      <td>-10.798035</td>\n",
       "      <td>-12.184635</td>\n",
       "      <td>-12.435873</td>\n",
       "      <td>-12.172310</td>\n",
       "      <td>...</td>\n",
       "      <td>6.357663</td>\n",
       "      <td>14.041871</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22.170889</td>\n",
       "      <td>4.843327</td>\n",
       "      <td>8.212131</td>\n",
       "      <td>-2.425146</td>\n",
       "      <td>1.250523</td>\n",
       "      <td>4.120774</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-3.183308</td>\n",
       "      <td>-8.890593</td>\n",
       "      <td>-7.111775</td>\n",
       "      <td>-6.126686</td>\n",
       "      <td>-10.196569</td>\n",
       "      <td>-9.468049</td>\n",
       "      <td>-9.430181</td>\n",
       "      <td>-10.720062</td>\n",
       "      <td>-10.895193</td>\n",
       "      <td>-10.685274</td>\n",
       "      <td>...</td>\n",
       "      <td>6.530216</td>\n",
       "      <td>14.796432</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>23.938522</td>\n",
       "      <td>5.237946</td>\n",
       "      <td>8.565498</td>\n",
       "      <td>-1.919751</td>\n",
       "      <td>1.358263</td>\n",
       "      <td>4.406640</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-2.292382</td>\n",
       "      <td>-6.725798</td>\n",
       "      <td>-5.534805</td>\n",
       "      <td>-4.750167</td>\n",
       "      <td>-8.130107</td>\n",
       "      <td>-7.449575</td>\n",
       "      <td>-7.449575</td>\n",
       "      <td>-8.479520</td>\n",
       "      <td>-8.656891</td>\n",
       "      <td>-8.508699</td>\n",
       "      <td>...</td>\n",
       "      <td>12.381601</td>\n",
       "      <td>26.284310</td>\n",
       "      <td>7.042618e+00</td>\n",
       "      <td>38.202807</td>\n",
       "      <td>21.824992</td>\n",
       "      <td>14.317385</td>\n",
       "      <td>4.444975</td>\n",
       "      <td>8.413209</td>\n",
       "      <td>9.312726</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Angle2        Angle3        Angle4        Angle5        Angle6  \\\n",
       "count  10684.000000  10684.000000  10684.000000  10684.000000  10684.000000   \n",
       "mean      -3.644671     -9.885094     -7.986397     -6.860374    -11.350325   \n",
       "std        0.522680      1.167194      0.975713      0.852689      1.292482   \n",
       "min       -4.935881    -12.809498    -10.437004     -8.957523    -14.576502   \n",
       "25%       -4.034503    -10.803379     -8.684925     -7.472805    -12.288738   \n",
       "50%       -3.751080    -10.125673     -8.212203     -7.032201    -11.620262   \n",
       "75%       -3.183308     -8.890593     -7.111775     -6.126686    -10.196569   \n",
       "max       -2.292382     -6.725798     -5.534805     -4.750167     -8.130107   \n",
       "\n",
       "             Angle7        Angle8        Angle9       Angle10       Angle11  \\\n",
       "count  10684.000000  10684.000000  10684.000000  10684.000000  10684.000000   \n",
       "mean     -10.551820    -10.551820    -11.931749    -12.164337    -11.907007   \n",
       "std        1.275340      1.251084      1.427203      1.416860      1.371840   \n",
       "min      -13.703503    -13.703503    -15.460537    -15.720765    -15.354577   \n",
       "25%      -11.463168    -11.438667    -12.937993    -13.179128    -12.893056   \n",
       "50%      -10.796308    -10.798035    -12.184635    -12.435873    -12.172310   \n",
       "75%       -9.468049     -9.430181    -10.720062    -10.895193    -10.685274   \n",
       "max       -7.449575     -7.449575     -8.479520     -8.656891     -8.508699   \n",
       "\n",
       "       ...      Branch12      Branch13      Branch14      Branch15  \\\n",
       "count  ...  10684.000000  10684.000000  1.068400e+04  10684.000000   \n",
       "mean   ...      6.103789     13.862711 -3.657806e-07     21.892834   \n",
       "std    ...      1.633094      3.198992  2.434109e+00      5.329356   \n",
       "min    ...      1.130133      4.089672 -7.042618e+00      9.431774   \n",
       "25%    ...      5.507815     12.777745  0.000000e+00     19.060383   \n",
       "50%    ...      6.357663     14.041871  0.000000e+00     22.170889   \n",
       "75%    ...      6.530216     14.796432  0.000000e+00     23.938522   \n",
       "max    ...     12.381601     26.284310  7.042618e+00     38.202807   \n",
       "\n",
       "           Branch16      Branch17      Branch18      Branch19      Branch20  \\\n",
       "count  10684.000000  10684.000000  10684.000000  10684.000000  10684.000000   \n",
       "mean       4.804057      8.078886     -2.338343      1.223160      4.003366   \n",
       "std        5.791752      1.935667      2.119438      2.048785      1.339676   \n",
       "min      -11.918270      2.808237    -10.444071     -5.988031     -0.099512   \n",
       "25%        4.402054      7.426043     -2.612391      1.065833      3.382496   \n",
       "50%        4.843327      8.212131     -2.425146      1.250523      4.120774   \n",
       "75%        5.237946      8.565498     -1.919751      1.358263      4.406640   \n",
       "max       21.824992     14.317385      4.444975      8.413209      9.312726   \n",
       "\n",
       "              Label  \n",
       "count  10684.000000  \n",
       "mean      10.242044  \n",
       "std       13.294249  \n",
       "min        0.000000  \n",
       "25%        3.000000  \n",
       "50%        7.000000  \n",
       "75%       12.000000  \n",
       "max       59.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_file = MAIN_FOLDER / \"data\\\\case1_train.csv\"\n",
    "processed_test_file = MAIN_FOLDER / \"data\\\\case3_test.csv\"\n",
    "\n",
    "def catter(label):\n",
    "    if label == \"Normal\":\n",
    "        return 0\n",
    "    else:\n",
    "        num = [int(x) for x in label.split() if x.isdigit()]\n",
    "        return num[0]\n",
    "\n",
    "def label_fix(label):\n",
    "    if label == 1010:\n",
    "        return 10\n",
    "    elif label == 1111:\n",
    "        return 11\n",
    "    elif label == 1212:\n",
    "        return 12\n",
    "    elif label == 1313:\n",
    "        return 13\n",
    "    elif label == 1414:\n",
    "        return 14\n",
    "    else:\n",
    "        return label\n",
    "    \n",
    "\n",
    "train_pd = pd.read_csv(TRAIN_FILE)\n",
    "train_pd\n",
    "print(train_pd[train_pd.isna().any(axis=1)])\n",
    "train_pd[\"Label\"] = train_pd[\"Label\"].apply(catter)\n",
    "train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Angle2, Angle3, Angle4, Angle5, Angle6, Angle7, Angle8, Angle9, Angle10, Angle11, Angle12, Angle13, Angle14, Branch1, Branch2, Branch3, Branch4, Branch5, Branch6, Branch7, Branch8, Branch9, Branch10, Branch11, Branch12, Branch13, Branch14, Branch15, Branch16, Branch17, Branch18, Branch19, Branch20, Label]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 34 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angle2</th>\n",
       "      <th>Angle3</th>\n",
       "      <th>Angle4</th>\n",
       "      <th>Angle5</th>\n",
       "      <th>Angle6</th>\n",
       "      <th>Angle7</th>\n",
       "      <th>Angle8</th>\n",
       "      <th>Angle9</th>\n",
       "      <th>Angle10</th>\n",
       "      <th>Angle11</th>\n",
       "      <th>...</th>\n",
       "      <th>Branch12</th>\n",
       "      <th>Branch13</th>\n",
       "      <th>Branch14</th>\n",
       "      <th>Branch15</th>\n",
       "      <th>Branch16</th>\n",
       "      <th>Branch17</th>\n",
       "      <th>Branch18</th>\n",
       "      <th>Branch19</th>\n",
       "      <th>Branch20</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>1.068400e+04</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "      <td>10684.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.392706</td>\n",
       "      <td>-9.225727</td>\n",
       "      <td>-7.490133</td>\n",
       "      <td>-6.466731</td>\n",
       "      <td>-10.923167</td>\n",
       "      <td>-10.073946</td>\n",
       "      <td>-10.073946</td>\n",
       "      <td>-11.463768</td>\n",
       "      <td>-11.703609</td>\n",
       "      <td>-11.462770</td>\n",
       "      <td>...</td>\n",
       "      <td>6.081272</td>\n",
       "      <td>13.785654</td>\n",
       "      <td>8.093411e-07</td>\n",
       "      <td>22.049776</td>\n",
       "      <td>4.953864</td>\n",
       "      <td>8.178325</td>\n",
       "      <td>-2.188486</td>\n",
       "      <td>1.201756</td>\n",
       "      <td>3.904733</td>\n",
       "      <td>10.242231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.609407</td>\n",
       "      <td>1.429952</td>\n",
       "      <td>1.155298</td>\n",
       "      <td>0.982335</td>\n",
       "      <td>1.396991</td>\n",
       "      <td>1.404112</td>\n",
       "      <td>1.384133</td>\n",
       "      <td>1.537724</td>\n",
       "      <td>1.526840</td>\n",
       "      <td>1.477777</td>\n",
       "      <td>...</td>\n",
       "      <td>1.578845</td>\n",
       "      <td>3.093755</td>\n",
       "      <td>2.320763e+00</td>\n",
       "      <td>5.147532</td>\n",
       "      <td>5.563867</td>\n",
       "      <td>1.869044</td>\n",
       "      <td>2.047925</td>\n",
       "      <td>1.973673</td>\n",
       "      <td>1.307572</td>\n",
       "      <td>13.294288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.903846</td>\n",
       "      <td>-12.773253</td>\n",
       "      <td>-10.340843</td>\n",
       "      <td>-8.885402</td>\n",
       "      <td>-14.524701</td>\n",
       "      <td>-13.621052</td>\n",
       "      <td>-13.621052</td>\n",
       "      <td>-15.386231</td>\n",
       "      <td>-15.651771</td>\n",
       "      <td>-15.286318</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159580</td>\n",
       "      <td>4.106071</td>\n",
       "      <td>-7.029676e+00</td>\n",
       "      <td>9.431774</td>\n",
       "      <td>-11.852837</td>\n",
       "      <td>2.860472</td>\n",
       "      <td>-10.427130</td>\n",
       "      <td>-5.985022</td>\n",
       "      <td>-0.099512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.847830</td>\n",
       "      <td>-10.288827</td>\n",
       "      <td>-8.365211</td>\n",
       "      <td>-7.202318</td>\n",
       "      <td>-11.961840</td>\n",
       "      <td>-11.114854</td>\n",
       "      <td>-11.106133</td>\n",
       "      <td>-12.572796</td>\n",
       "      <td>-12.816852</td>\n",
       "      <td>-12.549389</td>\n",
       "      <td>...</td>\n",
       "      <td>5.440254</td>\n",
       "      <td>12.673386</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>19.229689</td>\n",
       "      <td>4.540585</td>\n",
       "      <td>7.591718</td>\n",
       "      <td>-2.549857</td>\n",
       "      <td>1.046756</td>\n",
       "      <td>3.236500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.497695</td>\n",
       "      <td>-9.475194</td>\n",
       "      <td>-7.736021</td>\n",
       "      <td>-6.636011</td>\n",
       "      <td>-11.309001</td>\n",
       "      <td>-10.416109</td>\n",
       "      <td>-10.462350</td>\n",
       "      <td>-11.869445</td>\n",
       "      <td>-12.169356</td>\n",
       "      <td>-11.909514</td>\n",
       "      <td>...</td>\n",
       "      <td>6.331139</td>\n",
       "      <td>13.989556</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>22.364242</td>\n",
       "      <td>4.986078</td>\n",
       "      <td>8.298088</td>\n",
       "      <td>-2.315938</td>\n",
       "      <td>1.224271</td>\n",
       "      <td>4.060306</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.935390</td>\n",
       "      <td>-8.191471</td>\n",
       "      <td>-6.614963</td>\n",
       "      <td>-5.711877</td>\n",
       "      <td>-9.822656</td>\n",
       "      <td>-8.973802</td>\n",
       "      <td>-8.973802</td>\n",
       "      <td>-10.282538</td>\n",
       "      <td>-10.500584</td>\n",
       "      <td>-10.296687</td>\n",
       "      <td>...</td>\n",
       "      <td>6.517659</td>\n",
       "      <td>14.716354</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>24.123869</td>\n",
       "      <td>5.363282</td>\n",
       "      <td>8.658781</td>\n",
       "      <td>-1.742206</td>\n",
       "      <td>1.341936</td>\n",
       "      <td>4.355144</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-1.787035</td>\n",
       "      <td>-5.256002</td>\n",
       "      <td>-4.304178</td>\n",
       "      <td>-3.804625</td>\n",
       "      <td>-7.144336</td>\n",
       "      <td>-6.313136</td>\n",
       "      <td>-6.313136</td>\n",
       "      <td>-7.393421</td>\n",
       "      <td>-7.605750</td>\n",
       "      <td>-7.487309</td>\n",
       "      <td>...</td>\n",
       "      <td>12.376082</td>\n",
       "      <td>26.284310</td>\n",
       "      <td>7.030000e+00</td>\n",
       "      <td>38.173733</td>\n",
       "      <td>21.824992</td>\n",
       "      <td>14.317385</td>\n",
       "      <td>4.425189</td>\n",
       "      <td>8.401993</td>\n",
       "      <td>9.263333</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Angle2        Angle3        Angle4        Angle5        Angle6  \\\n",
       "count  10684.000000  10684.000000  10684.000000  10684.000000  10684.000000   \n",
       "mean      -3.392706     -9.225727     -7.490133     -6.466731    -10.923167   \n",
       "std        0.609407      1.429952      1.155298      0.982335      1.396991   \n",
       "min       -4.903846    -12.773253    -10.340843     -8.885402    -14.524701   \n",
       "25%       -3.847830    -10.288827     -8.365211     -7.202318    -11.961840   \n",
       "50%       -3.497695     -9.475194     -7.736021     -6.636011    -11.309001   \n",
       "75%       -2.935390     -8.191471     -6.614963     -5.711877     -9.822656   \n",
       "max       -1.787035     -5.256002     -4.304178     -3.804625     -7.144336   \n",
       "\n",
       "             Angle7        Angle8        Angle9       Angle10       Angle11  \\\n",
       "count  10684.000000  10684.000000  10684.000000  10684.000000  10684.000000   \n",
       "mean     -10.073946    -10.073946    -11.463768    -11.703609    -11.462770   \n",
       "std        1.404112      1.384133      1.537724      1.526840      1.477777   \n",
       "min      -13.621052    -13.621052    -15.386231    -15.651771    -15.286318   \n",
       "25%      -11.114854    -11.106133    -12.572796    -12.816852    -12.549389   \n",
       "50%      -10.416109    -10.462350    -11.869445    -12.169356    -11.909514   \n",
       "75%       -8.973802     -8.973802    -10.282538    -10.500584    -10.296687   \n",
       "max       -6.313136     -6.313136     -7.393421     -7.605750     -7.487309   \n",
       "\n",
       "       ...      Branch12      Branch13      Branch14      Branch15  \\\n",
       "count  ...  10684.000000  10684.000000  1.068400e+04  10684.000000   \n",
       "mean   ...      6.081272     13.785654  8.093411e-07     22.049776   \n",
       "std    ...      1.578845      3.093755  2.320763e+00      5.147532   \n",
       "min    ...      1.159580      4.106071 -7.029676e+00      9.431774   \n",
       "25%    ...      5.440254     12.673386  0.000000e+00     19.229689   \n",
       "50%    ...      6.331139     13.989556  0.000000e+00     22.364242   \n",
       "75%    ...      6.517659     14.716354  0.000000e+00     24.123869   \n",
       "max    ...     12.376082     26.284310  7.030000e+00     38.173733   \n",
       "\n",
       "           Branch16      Branch17      Branch18      Branch19      Branch20  \\\n",
       "count  10684.000000  10684.000000  10684.000000  10684.000000  10684.000000   \n",
       "mean       4.953864      8.178325     -2.188486      1.201756      3.904733   \n",
       "std        5.563867      1.869044      2.047925      1.973673      1.307572   \n",
       "min      -11.852837      2.860472    -10.427130     -5.985022     -0.099512   \n",
       "25%        4.540585      7.591718     -2.549857      1.046756      3.236500   \n",
       "50%        4.986078      8.298088     -2.315938      1.224271      4.060306   \n",
       "75%        5.363282      8.658781     -1.742206      1.341936      4.355144   \n",
       "max       21.824992     14.317385      4.425189      8.401993      9.263333   \n",
       "\n",
       "              Label  \n",
       "count  10684.000000  \n",
       "mean      10.242231  \n",
       "std       13.294288  \n",
       "min        0.000000  \n",
       "25%        3.000000  \n",
       "50%        7.000000  \n",
       "75%       12.000000  \n",
       "max       59.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd = pd.read_csv(TEST_FILE)\n",
    "print(test_pd[test_pd.isna().any(axis=1)])\n",
    "test_pd[\"Label\"] = test_pd[\"Label\"].apply(catter)\n",
    "test_pd[\"Label\"] = test_pd[\"Label\"].apply(label_fix)\n",
    "test_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pd.to_csv(processed_train_file)\n",
    "test_pd.to_csv(processed_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 59 27]\n",
      "[ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 27 59]\n"
     ]
    }
   ],
   "source": [
    "print(train_pd.Label.unique())\n",
    "print(test_pd.Label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def united_cat(df):\n",
    "    unq_labels = sorted(df[\"Label\"].unique())\n",
    "    label_dict = dict(zip(unq_labels, list(range(len(unq_labels)))))\n",
    "    df.Label = df[\"Label\"].map(label_dict)\n",
    "    return df, label_dict\n",
    "\n",
    "new_train_df, train_label_dict = united_cat(train_pd)\n",
    "new_test_df, test_label_dict = united_cat(test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = new_train_df.pop(\"Label\")\n",
    "y_train = to_categorical(y_train)\n",
    "x_train = new_train_df\n",
    "\n",
    "y_test= new_test_df.pop(\"Label\")\n",
    "y_test = to_categorical(y_test)\n",
    "x_test = new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle2     -3.644671e+00\n",
      "Angle3     -9.885094e+00\n",
      "Angle4     -7.986397e+00\n",
      "Angle5     -6.860374e+00\n",
      "Angle6     -1.135032e+01\n",
      "Angle7     -1.055182e+01\n",
      "Angle8     -1.055182e+01\n",
      "Angle9     -1.193175e+01\n",
      "Angle10    -1.216434e+01\n",
      "Angle11    -1.190701e+01\n",
      "Angle12    -1.224495e+01\n",
      "Angle13    -1.238503e+01\n",
      "Angle14    -1.318324e+01\n",
      "Branch1     1.075064e+02\n",
      "Branch2     5.368369e+01\n",
      "Branch3     5.501638e+01\n",
      "Branch4     4.297721e+01\n",
      "Branch5     3.227778e+01\n",
      "Branch6    -1.937585e+01\n",
      "Branch7    -4.667018e+01\n",
      "Branch8     2.189283e+01\n",
      "Branch9     1.277686e+01\n",
      "Branch10    3.336323e+01\n",
      "Branch11    4.884840e+00\n",
      "Branch12    6.103789e+00\n",
      "Branch13    1.386271e+01\n",
      "Branch14   -3.657806e-07\n",
      "Branch15    2.189283e+01\n",
      "Branch16    4.804057e+00\n",
      "Branch17    8.078886e+00\n",
      "Branch18   -2.338343e+00\n",
      "Branch19    1.223160e+00\n",
      "Branch20    4.003366e+00\n",
      "dtype: float64 Angle2        0.273169\n",
      "Angle3        1.362215\n",
      "Angle4        0.951927\n",
      "Angle5        0.727011\n",
      "Angle6        1.670353\n",
      "Angle7        1.626340\n",
      "Angle8        1.565065\n",
      "Angle9        2.036718\n",
      "Angle10       2.007305\n",
      "Angle11       1.881770\n",
      "Angle12       1.896029\n",
      "Angle13       1.885333\n",
      "Angle14       2.202255\n",
      "Branch1     229.063933\n",
      "Branch2      42.384365\n",
      "Branch3      33.237365\n",
      "Branch4      21.426008\n",
      "Branch5      12.134427\n",
      "Branch6       7.356930\n",
      "Branch7      80.801109\n",
      "Branch8       8.935240\n",
      "Branch9       2.435188\n",
      "Branch10     12.809927\n",
      "Branch11      4.248541\n",
      "Branch12      2.666747\n",
      "Branch13     10.232591\n",
      "Branch14      5.924334\n",
      "Branch15     28.399375\n",
      "Branch16     33.541248\n",
      "Branch17      3.746455\n",
      "Branch18      4.491599\n",
      "Branch19      4.197129\n",
      "Branch20      1.794563\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean_x = np.mean(x_train, axis=0)\n",
    "var_x = np.var(x_train, axis=0)\n",
    "print(mean_x, var_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Angle2        0.273169\n",
       "Angle3        1.362215\n",
       "Angle4        0.951927\n",
       "Angle5        0.727011\n",
       "Angle6        1.670353\n",
       "Angle7        1.626340\n",
       "Angle8        1.565065\n",
       "Angle9        2.036718\n",
       "Angle10       2.007305\n",
       "Angle11       1.881770\n",
       "Angle12       1.896029\n",
       "Angle13       1.885333\n",
       "Angle14       2.202255\n",
       "Branch1     229.063933\n",
       "Branch2      42.384365\n",
       "Branch3      33.237365\n",
       "Branch4      21.426008\n",
       "Branch5      12.134427\n",
       "Branch6       7.356930\n",
       "Branch7      80.801109\n",
       "Branch8       8.935240\n",
       "Branch9       2.435188\n",
       "Branch10     12.809927\n",
       "Branch11      4.248541\n",
       "Branch12      2.666747\n",
       "Branch13     10.232591\n",
       "Branch14      5.924334\n",
       "Branch15     28.399375\n",
       "Branch16     33.541248\n",
       "Branch17      3.746455\n",
       "Branch18      4.491599\n",
       "Branch19      4.197129\n",
       "Branch20      1.794563\n",
       "Name: var, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stats = pd.read_csv(MAIN_FOLDER / \"data\\\\x_stats.csv\", index_col=0)\n",
    "x_norm_layer = tf.keras.layers.experimental.preprocessing.Normalization(mean=x_stats.loc['mean'], variance=x_stats.loc['var'])\n",
    "x_train_norm = x_norm_layer(x_train)\n",
    "x_test_norm = x_norm_layer(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Angle2</th>\n",
       "      <th>Angle3</th>\n",
       "      <th>Angle4</th>\n",
       "      <th>Angle5</th>\n",
       "      <th>Angle6</th>\n",
       "      <th>Angle7</th>\n",
       "      <th>Angle8</th>\n",
       "      <th>Angle9</th>\n",
       "      <th>Angle10</th>\n",
       "      <th>Angle11</th>\n",
       "      <th>...</th>\n",
       "      <th>Branch11</th>\n",
       "      <th>Branch12</th>\n",
       "      <th>Branch13</th>\n",
       "      <th>Branch14</th>\n",
       "      <th>Branch15</th>\n",
       "      <th>Branch16</th>\n",
       "      <th>Branch17</th>\n",
       "      <th>Branch18</th>\n",
       "      <th>Branch19</th>\n",
       "      <th>Branch20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.644671</td>\n",
       "      <td>-9.885094</td>\n",
       "      <td>-7.986397</td>\n",
       "      <td>-6.860374</td>\n",
       "      <td>-11.350325</td>\n",
       "      <td>-10.55182</td>\n",
       "      <td>-10.551820</td>\n",
       "      <td>-11.931749</td>\n",
       "      <td>-12.164337</td>\n",
       "      <td>-11.907007</td>\n",
       "      <td>...</td>\n",
       "      <td>4.884840</td>\n",
       "      <td>6.103789</td>\n",
       "      <td>13.862711</td>\n",
       "      <td>-3.660000e-07</td>\n",
       "      <td>21.892834</td>\n",
       "      <td>4.804057</td>\n",
       "      <td>8.078886</td>\n",
       "      <td>-2.338343</td>\n",
       "      <td>1.223160</td>\n",
       "      <td>4.003366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>0.273169</td>\n",
       "      <td>1.362215</td>\n",
       "      <td>0.951927</td>\n",
       "      <td>0.727011</td>\n",
       "      <td>1.670353</td>\n",
       "      <td>1.62634</td>\n",
       "      <td>1.565065</td>\n",
       "      <td>2.036718</td>\n",
       "      <td>2.007305</td>\n",
       "      <td>1.881770</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248541</td>\n",
       "      <td>2.666747</td>\n",
       "      <td>10.232591</td>\n",
       "      <td>5.924334e+00</td>\n",
       "      <td>28.399375</td>\n",
       "      <td>33.541248</td>\n",
       "      <td>3.746455</td>\n",
       "      <td>4.491599</td>\n",
       "      <td>4.197129</td>\n",
       "      <td>1.794563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Angle2    Angle3    Angle4    Angle5     Angle6    Angle7     Angle8  \\\n",
       "mean -3.644671 -9.885094 -7.986397 -6.860374 -11.350325 -10.55182 -10.551820   \n",
       "var   0.273169  1.362215  0.951927  0.727011   1.670353   1.62634   1.565065   \n",
       "\n",
       "         Angle9    Angle10    Angle11  ...  Branch11  Branch12   Branch13  \\\n",
       "mean -11.931749 -12.164337 -11.907007  ...  4.884840  6.103789  13.862711   \n",
       "var    2.036718   2.007305   1.881770  ...  4.248541  2.666747  10.232591   \n",
       "\n",
       "          Branch14   Branch15   Branch16  Branch17  Branch18  Branch19  \\\n",
       "mean -3.660000e-07  21.892834   4.804057  8.078886 -2.338343  1.223160   \n",
       "var   5.924334e+00  28.399375  33.541248  3.746455  4.491599  4.197129   \n",
       "\n",
       "      Branch20  \n",
       "mean  4.003366  \n",
       "var   1.794563  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.9",
   "language": "python",
   "name": "venv3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
